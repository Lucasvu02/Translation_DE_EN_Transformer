{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = '/content/translatedataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UotZ4Jzk9aql",
        "outputId": "18ac5084-199d-4be2-ea85-75fc9367df2e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  de  \\\n",
            "0  Ursprünglich war die Schulhofsanierung sogar s...   \n",
            "1  Von daher werden sie gegen ihren Ex-Coach sich...   \n",
            "2  Sie sind nicht alle erfahrene Rennfahrer, sond...   \n",
            "3  In seinem Brief macht Snowden den deutschen Be...   \n",
            "4  Ein Anwohner im Bischof-Freundorfer-Weg meldet...   \n",
            "\n",
            "                                                  en  \n",
            "0  The school yard renovation was originally plan...  \n",
            "1  Consequently, they will be particularly motiva...  \n",
            "2  They're not all experienced racers, but people...  \n",
            "3  The letter extends an offer to cooperate with ...  \n",
            "4  The residents of the Bischof-Freundorfer-Weg r...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(data.info())\n",
        "\n",
        "print(data.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CXwugxwx9lW4",
        "outputId": "8d1a0fd9-fbb8-4895-e948-d311490432e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3003 entries, 0 to 3002\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   de      3003 non-null   object\n",
            " 1   en      3003 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 47.0+ KB\n",
            "None\n",
            "                                                       de  \\\n",
            "count                                                3003   \n",
            "unique                                               3003   \n",
            "top     Ursprünglich war die Schulhofsanierung sogar s...   \n",
            "freq                                                    1   \n",
            "\n",
            "                                                 en  \n",
            "count                                          3003  \n",
            "unique                                         3001  \n",
            "top     However, speaking the truth is not a crime.  \n",
            "freq                                              2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(data.isnull().sum())\n",
        "\n",
        "data = data.dropna()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIJighbw9pS6",
        "outputId": "4dc05cd2-8dc3-4c5c-a094-b2380f4461d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de    0\n",
            "en    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "source_texts = data['de']\n",
        "target_texts = data['en']\n",
        "\n",
        "for source, target in zip(source_texts.head(), target_texts.head()):\n",
        "    print(f\"Source: {source}\\nTarget: {target}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I1X7LQgQ9riL",
        "outputId": "144989d8-0121-4e63-a869-e8385277fb92"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: Ursprünglich war die Schulhofsanierung sogar schon in den Jahren 2008/2009 geplant, doch hohe unplanmäßige Ausgaben brachten eine Verschiebung.\n",
            "Target: The school yard renovation was originally planned back in 2008/2009, however, high unplanned expenses meant that the work had to be pushed back.\n",
            "\n",
            "Source: Von daher werden sie gegen ihren Ex-Coach sicher ganz besonders motiviert sein.\n",
            "Target: Consequently, they will be particularly motivated playing against their former coach.\n",
            "\n",
            "Source: Sie sind nicht alle erfahrene Rennfahrer, sondern Leute, die auf der Suche nach Spannung und Abenteuer sind sowie nach einem erreichbaren Weg zu Weltklasse-Veranstaltungen.\n",
            "Target: They're not all experienced racers, but people looking for excitement and adventure, and an achievable path towards world-class events.\n",
            "\n",
            "Source: In seinem Brief macht Snowden den deutschen Behörden ein Angebot der Zusammenarbeit, „wenn die Schwierigkeiten rund um die humanitäre Situation gelöst wurden“.\n",
            "Target: The letter extends an offer to cooperate with German authorities \"when the difficulties of this humanitarian situation have been resolved.\"\n",
            "\n",
            "Source: Ein Anwohner im Bischof-Freundorfer-Weg meldete, dass sein Pkw mit Klopapier eingewickelt und seine Radzierblenden entwendet wurden.\n",
            "Target: The residents of the Bischof-Freundorfer-Weg reported that a car was wrapped in toilet paper and its wheel trims stolen.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_file_path = '/content/processed_translatedataset.csv'\n",
        "data.to_csv(processed_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "CcyDDdKm9zy7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "file_path = '/content/translatedataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "data = data.dropna()\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "source_texts = train_data['de'].tolist()\n",
        "target_texts = train_data['en'].tolist()\n"
      ],
      "metadata": {
        "id": "gWSjdKxT99GO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "source_tokenizer = Tokenizer()\n",
        "target_tokenizer = Tokenizer()\n",
        "\n",
        "\n",
        "source_tokenizer.fit_on_texts(source_texts)\n",
        "target_tokenizer.fit_on_texts(target_texts)\n",
        "\n",
        "\n",
        "source_sequences = source_tokenizer.texts_to_sequences(source_texts)\n",
        "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
        "\n",
        "\n",
        "max_source_len = max(len(seq) for seq in source_sequences)\n",
        "max_target_len = max(len(seq) for seq in target_sequences)\n",
        "\n",
        "source_padded = pad_sequences(source_sequences, maxlen=max_source_len, padding='post')\n",
        "target_padded = pad_sequences(target_sequences, maxlen=max_target_len, padding='post')\n",
        "\n",
        "\n",
        "X_train = source_padded\n",
        "y_train = target_padded\n"
      ],
      "metadata": {
        "id": "8f0pMAkC9_th"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "vocab_size_source = len(source_tokenizer.word_index) + 1\n",
        "vocab_size_target = len(target_tokenizer.word_index) + 1\n",
        "embedding_dim = 256\n",
        "hidden_units = 512\n",
        "\n",
        "\n",
        "encoder_inputs = Input(shape=(max_source_len,))\n",
        "encoder_embedding = Embedding(vocab_size_source, embedding_dim)(encoder_inputs)\n",
        "encoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "decoder_inputs = Input(shape=(max_target_len,))\n",
        "decoder_embedding = Embedding(vocab_size_target, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size_target, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit([X_train, y_train], y_train, epochs=10, batch_size=64, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKoGfcI--DPc",
        "outputId": "e254cb07-fed2-444d-a4c1-3828e5e40ea3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 9s/step - accuracy: 0.6226 - loss: 5.2514 - val_accuracy: 0.7059 - val_loss: 2.3493\n",
            "Epoch 2/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 8s/step - accuracy: 0.7213 - loss: 2.1431 - val_accuracy: 0.7278 - val_loss: 2.1340\n",
            "Epoch 3/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 8s/step - accuracy: 0.7283 - loss: 2.0253 - val_accuracy: 0.7281 - val_loss: 2.0528\n",
            "Epoch 4/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 8s/step - accuracy: 0.7373 - loss: 1.8619 - val_accuracy: 0.7283 - val_loss: 1.9848\n",
            "Epoch 5/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 8s/step - accuracy: 0.7360 - loss: 1.8132 - val_accuracy: 0.7495 - val_loss: 1.9403\n",
            "Epoch 6/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 8s/step - accuracy: 0.7487 - loss: 1.7648 - val_accuracy: 0.7504 - val_loss: 1.9001\n",
            "Epoch 7/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 8s/step - accuracy: 0.7593 - loss: 1.6936 - val_accuracy: 0.7625 - val_loss: 1.8561\n",
            "Epoch 8/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 8s/step - accuracy: 0.7656 - loss: 1.6628 - val_accuracy: 0.7696 - val_loss: 1.8043\n",
            "Epoch 9/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 8s/step - accuracy: 0.7819 - loss: 1.5373 - val_accuracy: 0.7800 - val_loss: 1.7550\n",
            "Epoch 10/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 8s/step - accuracy: 0.7867 - loss: 1.4987 - val_accuracy: 0.7948 - val_loss: 1.7048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.save('/content/translation_model.keras')\n"
      ],
      "metadata": {
        "id": "iY_5Dl_XIiy0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "model = load_model('/content/translation_model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nesq02ooIm2y",
        "outputId": "89906385-7ef6-456f-dbe2-bb1243076116"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "checkpoint_path = '/content/translation_model_checkpoint.keras'\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             verbose=1)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train, y_train],\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate([X_test, y_test], y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "collapsed": true,
        "id": "X5U1vICdI2kG",
        "outputId": "7187e055-9f34-4017-c1ab-dd642361271b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8020 - loss: 1.4283\n",
            "Epoch 1: val_loss improved from inf to 1.69373, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 8s/step - accuracy: 0.8020 - loss: 1.4284 - val_accuracy: 0.7944 - val_loss: 1.6937\n",
            "Epoch 2/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.7980 - loss: 1.4359\n",
            "Epoch 2: val_loss improved from 1.69373 to 1.68760, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 9s/step - accuracy: 0.7981 - loss: 1.4353 - val_accuracy: 0.7960 - val_loss: 1.6876\n",
            "Epoch 3/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8040 - loss: 1.4016\n",
            "Epoch 3: val_loss improved from 1.68760 to 1.68173, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 8s/step - accuracy: 0.8040 - loss: 1.4016 - val_accuracy: 0.7973 - val_loss: 1.6817\n",
            "Epoch 4/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8059 - loss: 1.3825\n",
            "Epoch 4: val_loss improved from 1.68173 to 1.67690, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 8s/step - accuracy: 0.8059 - loss: 1.3827 - val_accuracy: 0.7992 - val_loss: 1.6769\n",
            "Epoch 5/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8062 - loss: 1.3829\n",
            "Epoch 5: val_loss improved from 1.67690 to 1.67127, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 9s/step - accuracy: 0.8062 - loss: 1.3828 - val_accuracy: 0.8004 - val_loss: 1.6713\n",
            "Epoch 6/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8075 - loss: 1.3746\n",
            "Epoch 6: val_loss improved from 1.67127 to 1.66636, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 9s/step - accuracy: 0.8076 - loss: 1.3745 - val_accuracy: 0.8021 - val_loss: 1.6664\n",
            "Epoch 7/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8039 - loss: 1.3920\n",
            "Epoch 7: val_loss improved from 1.66636 to 1.66070, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 9s/step - accuracy: 0.8041 - loss: 1.3910 - val_accuracy: 0.8032 - val_loss: 1.6607\n",
            "Epoch 8/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8079 - loss: 1.3617\n",
            "Epoch 8: val_loss improved from 1.66070 to 1.65516, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 8s/step - accuracy: 0.8080 - loss: 1.3613 - val_accuracy: 0.8038 - val_loss: 1.6552\n",
            "Epoch 9/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8103 - loss: 1.3454\n",
            "Epoch 9: val_loss improved from 1.65516 to 1.64980, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 8s/step - accuracy: 0.8103 - loss: 1.3451 - val_accuracy: 0.8050 - val_loss: 1.6498\n",
            "Epoch 10/10\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8135 - loss: 1.3214\n",
            "Epoch 10: val_loss improved from 1.64980 to 1.64536, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 8s/step - accuracy: 0.8134 - loss: 1.3216 - val_accuracy: 0.8058 - val_loss: 1.6454\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-aeed67f4567a>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Đánh giá mô hình trên tập kiểm tra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_save_path = '/content/translation_model_final.keras'\n",
        "\n",
        "\n",
        "model.save(model_save_path)\n",
        "print(f'Model saved to {model_save_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "99qhWZBSTcpV",
        "outputId": "c222ff6c-8315-4bbd-b3bf-a298c70358ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/translation_model_final.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "model_load_path = '/content/translation_model_final.keras'\n",
        "\n",
        "\n",
        "model = load_model(model_load_path)\n",
        "print(f'Model loaded from {model_load_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2na5mgIjTifX",
        "outputId": "37cdd52a-d514-43c0-b7df-62417000590a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from /content/translation_model_final.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.00005)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "checkpoint_path = '/content/translation_model_checkpoint.keras'\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             verbose=1)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train, y_train],\n",
        "    y_train,\n",
        "    epochs=1,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aUhdCoNTkIO",
        "outputId": "4f5d7c6f-dfea-4692-d335-9f4ce7114db3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8146 - loss: 1.3079\n",
            "Epoch 1: val_loss improved from inf to 1.63920, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 9s/step - accuracy: 0.8146 - loss: 1.3082 - val_accuracy: 0.8065 - val_loss: 1.6392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_save_path = '/content/translation_model_final.keras'\n",
        "\n",
        "\n",
        "model.save(model_save_path)\n",
        "print(f'Model saved to {model_save_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qaf77inpU_hw",
        "outputId": "8a592ed6-394a-4c9a-f612-57c624a46bba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/translation_model_final.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=False,\n",
        "                             verbose=1)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train, y_train],\n",
        "    y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt6bHcAHVOY3",
        "outputId": "39106339-0c34-4682-8512-520a8728afb5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8157 - loss: 1.2974\n",
            "Epoch 1: val_loss improved from inf to 1.63557, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 8s/step - accuracy: 0.8157 - loss: 1.2978 - val_accuracy: 0.8070 - val_loss: 1.6356\n",
            "Epoch 2/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8142 - loss: 1.3082\n",
            "Epoch 2: val_loss improved from 1.63557 to 1.63266, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 9s/step - accuracy: 0.8142 - loss: 1.3081 - val_accuracy: 0.8075 - val_loss: 1.6327\n",
            "Epoch 3/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8161 - loss: 1.2945\n",
            "Epoch 3: val_loss improved from 1.63266 to 1.62995, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 8s/step - accuracy: 0.8161 - loss: 1.2947 - val_accuracy: 0.8078 - val_loss: 1.6300\n",
            "Epoch 4/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8154 - loss: 1.2937\n",
            "Epoch 4: val_loss improved from 1.62995 to 1.62737, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 9s/step - accuracy: 0.8154 - loss: 1.2937 - val_accuracy: 0.8080 - val_loss: 1.6274\n",
            "Epoch 5/5\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8141 - loss: 1.3018\n",
            "Epoch 5: val_loss improved from 1.62737 to 1.62516, saving model to /content/translation_model_checkpoint.keras\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 8s/step - accuracy: 0.8141 - loss: 1.3014 - val_accuracy: 0.8082 - val_loss: 1.6252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_save_path = '/content/translation_model_final.keras'\n",
        "\n",
        "model.save(model_save_path)\n",
        "print(f'Model saved to {model_save_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfbe2DDPc7y9",
        "outputId": "ba3c466a-941e-4a2e-f706-ab46032178bb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/translation_model_final.keras\n"
          ]
        }
      ]
    }
  ]
}